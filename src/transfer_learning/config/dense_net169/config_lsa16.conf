[TRAIN]
    # Dataset name
    data.dataset = lsa16
    # Name of the splitting
    data.split =
    # Number of episodes in one epoch
    data.episodes = 100
    # Flag to use CUDA
    data.cuda = 0
    # Number of GPU if data.cuda is set to 1
    data.gpu = 0

    data.rotation_range = 10
    data.width_shift_range = 0.10
    data.height_shift_range = 0.10
    data.horizontal_flip = True

    # 0.33, 0.5, 0.64, 0.75
    data.train_size = 0.75
    data.test_size = 0.25
    data.batch_size = 16
    data.weight_classes =

    # Path to the saved model
    model.save_path = ./results/lsa16/dense_net201/checkpoints/checkpoint.lsa16_dense_net201_{epoch:02d}_{val_loss:.2f}_{val_accuracy:.2f}.h5
    # <type> = vanilla | augmentation
    model.type = augmentation
    model.name = DenseNet201
    model.weights = 

    # Flag to write output to file
    output.write = 1
    # Path to debug info
    output.train_path = ./results/lsa16/dense_net201/results/lsa16_dense_net201_{}.csv
    # Config file
    output.config_path = ./results/lsa16/dense_net201/config/lsa16_dense_net201_{}.json
    # tensorboard summary
    summary.save_path = ./results/lsa16/dense_net201/summaries/{}/{}_{}_{}_{}

    # Number of epochs to train
    train.epochs = 100
    # Name of the optimizer
    train.optim_method = Adam
    # Learning rate
    train.lr = 0.001
    # Early stopping patience
    train.patience = 15

[EVAL]
    # data
    data.dataset = lsa16
    data.split =
    data.cuda = 1
    data.gpu = 0
    
    data.rotation_range = 10
    data.width_shift_range = 0.10
    data.height_shift_range = 0.10
    data.horizontal_flip = True

    data.test_size =
    data.batch_size = 16
    data.weight_classes =

    # model
    # you should write the complete path to run an specific model
    model.save_path = ./results/lsa16/dense_net201/checkpoints/checkpoint.lsa16_dense_net201_{epoch:02d}_{val_loss:.2f}_{val_accuracy:.2f}.h5
    model.type = augmentation
    model.name = DenseNet201
    model.weights = 
